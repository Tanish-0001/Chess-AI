{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T17:24:53.772206Z",
     "start_time": "2024-08-03T17:24:51.247740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from generate_training_data import ChessDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ],
   "id": "8c779722a1df639",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T17:24:54.745476Z",
     "start_time": "2024-08-03T17:24:53.773213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(14 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.out1 = nn.Linear(256, 64)  # source square of the piece it wishes to move\n",
    "        self.out2 = nn.Linear(256, 64)  # target square where it wants to piece to land\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc2(self.relu(self.fc1(x))))\n",
    "        from_square = self.out1(x)\n",
    "        to_square = self.out2(x)\n",
    "        return from_square, to_square\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ChessNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate scheduler\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "id": "3a900cee07a69b2c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T16:39:51.516799Z",
     "start_time": "2024-08-02T16:39:51.503445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Will stop the training if loss doesn't improve for a given number of epochs'\n",
    "    \"\"\"\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, prev_loss, curr_loss):\n",
    "        if abs(curr_loss - prev_loss) < self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "                \n",
    "early_stopping = EarlyStopping(tolerance=2, min_delta=0.0001)"
   ],
   "id": "efad094ec706fe43",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:50:49.259877Z",
     "start_time": "2024-07-29T07:44:16.553154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "train_data = ChessDataset(num_examples=32768)\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ],
   "id": "f001c7fa4888c4b2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:53:58.076875Z",
     "start_time": "2024-07-29T07:51:20.327340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 100\n",
    "prev_loss = float(\"inf\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, (x_train, y_train) in enumerate(train_data_loader):\n",
    "        batch_x = x_train.to(device)\n",
    "        sources = y_train[:, 0].to(device)\n",
    "        destinations = y_train[:, 1].to(device)\n",
    "        \n",
    "        batch_x = batch_x.reshape(batch_size, 14 * 8 * 8)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_source, predicted_destination = model(batch_x)\n",
    "\n",
    "        loss_from = loss_fn(predicted_source, sources)\n",
    "        loss_to = loss_fn(predicted_destination, destinations)\n",
    "\n",
    "        loss = loss_from + loss_to\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()  # Update the learning rate\n",
    "    \n",
    "    early_stopping(curr_loss=loss.item(), prev_loss=prev_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    prev_loss = loss.item()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} Loss: {loss.item():.4f}')\n",
    "        \n",
    "print(\"Final loss: \", loss.item())\n"
   ],
   "id": "119a19be54c5cafd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Loss: 6.9434\n",
      "Epoch 11/100 Loss: 2.8964\n",
      "Epoch 21/100 Loss: 2.7492\n",
      "Epoch 31/100 Loss: 2.4871\n",
      "Epoch 41/100 Loss: 2.5214\n",
      "Epoch 51/100 Loss: 2.4575\n",
      "Epoch 61/100 Loss: 2.5155\n",
      "Epoch 71/100 Loss: 2.6629\n",
      "Epoch 81/100 Loss: 2.6233\n",
      "Epoch 91/100 Loss: 2.4574\n",
      "Final loss:  2.733704090118408\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T07:54:45.071511Z",
     "start_time": "2024-07-29T07:54:45.058485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PATH = 'chess_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ],
   "id": "aed499d9fdc3bcc8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T16:41:08.960261Z",
     "start_time": "2024-08-02T16:41:08.752856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chess.engine\n",
    "\n",
    "engine = chess.engine.SimpleEngine.popen_uci(r\"C:\\Users\\jaint\\stockfish\\stockfish-windows-x86-64-avx2\")  \n",
    "# stockfish's evaluation for a position will be the reward for the RL algorithm\n",
    "\n",
    "def evaluate_board(board):\n",
    "    result = engine.analyse(board, chess.engine.Limit(time=0.1))  # gives stockfish score of the current position (scaled up by 100)\n",
    "    evaluation = result[\"score\"]\n",
    "    if evaluation.is_mate():  # score() returns None if the position has forced mate - so it is handled separately\n",
    "        plies = evaluation.pov(chess.WHITE).mate()\n",
    "        if plies > 0:  # White is the one checkmating\n",
    "            return (21 - plies) * 100  # return a large positive score that decays with the number of moves till mate\n",
    "        return (-21 - plies) * 100  # Black is the one checkmating\n",
    "    return result[\"score\"].relative.score()\n"
   ],
   "id": "5909c040a5a7361a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T16:40:42.005382Z",
     "start_time": "2024-08-02T16:40:41.988449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChessNet().to(device)\n",
    "model.load_state_dict(torch.load('chess_net.pth'))"
   ],
   "id": "4eda0cb230b92308",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T17:23:20.713153Z",
     "start_time": "2024-08-02T16:50:09.265448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from chess_board import get_chess_board, square_to_uci\n",
    "memory = []\n",
    "gamma = 0.99\n",
    "batch_size = 64\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def choose_action(board):\n",
    "    if random.random() < 0.2:  # 20% chance to make a random legal move\n",
    "        return random.choice(list(board.legal_moves))\n",
    "    else:\n",
    "        tensor = torch.from_numpy(get_chess_board(board).reshape(-1, 14 * 8 * 8).astype(np.float32)).to(device)\n",
    "        q_values = model(tensor)\n",
    "        move_source, move_destination = q_values\n",
    "        move_source = square_to_uci(torch.argmax(move_source, 1)[0].data.item())\n",
    "        move_destination = square_to_uci(torch.argmax(move_destination, 1)[0].data.item())\n",
    "        if move_source == move_destination:  # NULL move\n",
    "            UCI = '0000'\n",
    "        else:\n",
    "            UCI = move_source + move_destination\n",
    "        \n",
    "        return chess.Move.from_uci(UCI)  # convert it to chess' Move class\n",
    "    \n",
    "    \n",
    "def train_model():\n",
    "\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    batch = random.sample(memory, batch_size)\n",
    "    states, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "    states = torch.stack(states).to(device)  # stack all the states together to pass into model\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float32).reshape(batch_size, -1).to(device)  # Convert rewards to a tensor\n",
    "    dones = torch.tensor(dones, dtype=torch.float32).reshape(batch_size, -1).to(device)  # Convert dones to a tensor\n",
    "\n",
    "    q_values = model(states)  # Predict Q-values for current states\n",
    "    from_squares = q_values[0]\n",
    "    to_squares = q_values[1]\n",
    "\n",
    "    from_squares = torch.argmax(from_squares, dim=2)  # get the actual square because MSE loss is used\n",
    "    to_squares = torch.argmax(to_squares, dim=2)\n",
    "\n",
    "    next_from_squares = torch.zeros(size=(batch_size, 1, 64)) \n",
    "    next_to_squares = torch.zeros(size=(batch_size, 1, 64))\n",
    "    non_terminal_mask = torch.tensor([s is not None for s in next_states], dtype=torch.bool)  \n",
    "    # in the case for terminal states (i.e, no next state) the next state is None so it needs to be ignored\n",
    "\n",
    "    if non_terminal_mask.any():\n",
    "        non_terminal_next_states = torch.stack([s for s in next_states if s is not None])\n",
    "        next_from_squares[non_terminal_mask], next_to_squares[non_terminal_mask] = model(non_terminal_next_states)\n",
    "\n",
    "\n",
    "    next_from_squares = torch.argmax(next_from_squares, dim=2)\n",
    "    next_to_squares = torch.argmax(next_to_squares, dim=2)\n",
    "\n",
    "    target_from_values = rewards + gamma * next_from_squares * (1 - dones)  # bellman equation\n",
    "    target_to_values = rewards + gamma * next_to_squares * (1 - dones)\n",
    "\n",
    "    loss_f = loss_fn(from_squares, target_from_values)\n",
    "    loss_t = loss_fn(to_squares, target_to_values)\n",
    "\n",
    "    loss = loss_f + loss_t\n",
    "    loss.requires_grad = True  # torch.argmax has requires_grad as False, so I explicitly set it to True\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "for episode in range(10000):\n",
    "    board = chess.Board()\n",
    "    # Make two random moves so that model doesn't just play the same game everytime\n",
    "    board.push(random.choice(list(board.legal_moves)))\n",
    "    board.push(random.choice(list(board.legal_moves)))\n",
    "    while not board.is_game_over():\n",
    "        state = torch.from_numpy(get_chess_board(board).reshape(-1, 14 * 8 * 8).astype(np.float32))\n",
    "        action = choose_action(board)\n",
    "\n",
    "        if action in board.legal_moves:\n",
    "            board.push(action)\n",
    "            next_state = torch.from_numpy(get_chess_board(board).reshape(-1, 14 * 8 * 8).astype(np.float32))\n",
    "            reward = evaluate_board(board)\n",
    "            done = board.is_game_over()\n",
    "        else:\n",
    "            reward = -15000\n",
    "            next_state = None\n",
    "            done = 1\n",
    "        memory.append((state, reward, next_state, done))\n",
    "        if done:\n",
    "            break\n",
    "    train_model()\n",
    "    if episode % 500 == 0:\n",
    "        print(f\"Episode: {episode + 1}\")\n"
   ],
   "id": "5cec1ac7b33611c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Episode: 501\n",
      "Episode: 1001\n",
      "Episode: 1501\n",
      "Episode: 2001\n",
      "Episode: 2501\n",
      "Episode: 3001\n",
      "Episode: 3501\n",
      "Episode: 4001\n",
      "Episode: 4501\n",
      "Episode: 5001\n",
      "Episode: 5501\n",
      "Episode: 6001\n",
      "Episode: 6501\n",
      "Episode: 7001\n",
      "Episode: 7501\n",
      "Episode: 8001\n",
      "Episode: 8501\n",
      "Episode: 9001\n",
      "Episode: 9501\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T09:29:18.381300Z",
     "start_time": "2024-08-03T09:29:18.365249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PATH = 'chess_net_linear_RL.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ],
   "id": "a4210075d80c09e8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T17:25:01.656021Z",
     "start_time": "2024-08-03T17:25:01.144140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing\n",
    "\n",
    "import chess\n",
    "from chess_board import get_chess_board, square_to_uci\n",
    "new_board = chess.Board()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    while not new_board.is_game_over():\n",
    "        featurized = torch.from_numpy(get_chess_board(new_board).reshape(-1, 14 * 8 * 8).astype(np.float32))\n",
    "        \n",
    "        predicted_source, predicted_destination = model(featurized)\n",
    "        source = square_to_uci(torch.argmax(predicted_source, 1)[0].data.item())\n",
    "        destination = square_to_uci(torch.argmax(predicted_destination, 1)[0].data.item())\n",
    "        \n",
    "        uci = source + destination\n",
    "        print(uci)\n",
    "        new_board.push_uci(uci)\n",
    "        "
   ],
   "id": "d46f0aa3be789d87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2e4\n",
      "e7e5\n",
      "g1f3\n",
      "b8c6\n",
      "f1c4\n",
      "g8f6\n",
      "d2d3\n",
      "f8d6\n",
      "e1g1\n",
      "e8g8\n",
      "b1c3\n",
      "a7c5\n"
     ]
    },
    {
     "ename": "IllegalMoveError",
     "evalue": "illegal uci: 'a7c5' in r1bq1rk1/pppp1ppp/2nb1n2/4p3/2B1P3/2NP1N2/PPP2PPP/R1BQ1RK1 b - - 4 6",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIllegalMoveError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m uci \u001B[38;5;241m=\u001B[39m source \u001B[38;5;241m+\u001B[39m destination\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(uci)\n\u001B[1;32m---> 18\u001B[0m \u001B[43mnew_board\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_uci\u001B[49m\u001B[43m(\u001B[49m\u001B[43muci\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\chess\\__init__.py:3164\u001B[0m, in \u001B[0;36mBoard.push_uci\u001B[1;34m(self, uci)\u001B[0m\n\u001B[0;32m   3151\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpush_uci\u001B[39m(\u001B[38;5;28mself\u001B[39m, uci: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Move:\n\u001B[0;32m   3152\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3153\u001B[0m \u001B[38;5;124;03m    Parses a move in UCI notation and puts it on the move stack.\u001B[39;00m\n\u001B[0;32m   3154\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3162\u001B[0m \u001B[38;5;124;03m        - :exc:`IllegalMoveError` if the UCI is illegal.\u001B[39;00m\n\u001B[0;32m   3163\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3164\u001B[0m     move \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_uci\u001B[49m\u001B[43m(\u001B[49m\u001B[43muci\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3165\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpush(move)\n\u001B[0;32m   3166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m move\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\chess\\__init__.py:3147\u001B[0m, in \u001B[0;36mBoard.parse_uci\u001B[1;34m(self, uci)\u001B[0m\n\u001B[0;32m   3144\u001B[0m move \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_from_chess960(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchess960, move\u001B[38;5;241m.\u001B[39mfrom_square, move\u001B[38;5;241m.\u001B[39mto_square, move\u001B[38;5;241m.\u001B[39mpromotion, move\u001B[38;5;241m.\u001B[39mdrop)\n\u001B[0;32m   3146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_legal(move):\n\u001B[1;32m-> 3147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m IllegalMoveError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124millegal uci: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00muci\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfen()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m move\n",
      "\u001B[1;31mIllegalMoveError\u001B[0m: illegal uci: 'a7c5' in r1bq1rk1/pppp1ppp/2nb1n2/4p3/2B1P3/2NP1N2/PPP2PPP/R1BQ1RK1 b - - 4 6"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb3a2414f13df3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
